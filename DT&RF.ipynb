{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.feature_extraction.text as sktext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data, the data used in this script is SPAM data set.\n",
    "# The object 'data' is a dic that contains np.array 'training_data' and 'training_labels'.\n",
    "matfn='spam_data.mat'\n",
    "data=sio.loadmat(matfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the training set and validation set\n",
    "n_feature=data['training_data'].shape[1]\n",
    "label=np.unique(data['training_labels'][0])\n",
    "i=True\n",
    "while i is True:\n",
    "    valid_ind=random.sample(range(len(data['training_data'])),round(len(data['training_data'])*0.2))\n",
    "    train_ind=[i for i in range(len(data['training_data'])) if i not in valid_ind]    \n",
    "    valid_set=data['training_data'][valid_ind]\n",
    "    train_set=data['training_data'][train_ind]\n",
    "    valid_label=data['training_labels'][0][valid_ind]\n",
    "    train_label=data['training_labels'][0][train_ind]        \n",
    "    i= (False in [i in valid_label for i in label]) | (False in [i in train_label for i in label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Nodes:\n",
    "    def __init__(self,split_rule=(-1,None),label=None,left=None,right=None):\n",
    "        self.split_rule=split_rule # column index and criteria\n",
    "        self.label=label # leaf node label\n",
    "        self.left=left # nodes (<)\n",
    "        self.right=right # nodes (>=)\n",
    "        self.parent=None\n",
    "        self.depth=1\n",
    "        self.train_data=None\n",
    "        self.train_labels=None\n",
    "        \n",
    "    def GrowTree(self, max_depth, train_data, train_labels,random_feature=-1):\n",
    "        if (sum(train_labels)/len(train_labels))>0.95 or (sum(train_labels)/len(train_labels))<0.05 or len(train_labels)<10:\n",
    "            self.label=round((sum(train_labels)/len(train_labels)))\n",
    "            self.train_data=train_data\n",
    "            self.train_labels=train_labels\n",
    "        elif max_depth>0 and self.depth>max_depth:\n",
    "            self.label=round((sum(train_labels)/len(train_labels)))\n",
    "            self.train_data=train_data\n",
    "            self.train_labels=train_labels             \n",
    "        else:\n",
    "            if random_feature==-1:\n",
    "                self.split_rule=best_split(train_data,train_labels)\n",
    "            else:\n",
    "                sample_feature=random.sample(range(train_data.shape[1]),random_feature)\n",
    "                sample_data=train_data[...,sample_feature]\n",
    "                random_split_rule=best_split(sample_data,train_labels)\n",
    "                self.split_rule=(sample_feature[random_split_rule[0]],random_split_rule[1])          \n",
    "            #find best split rule, input train_data, train_labels, return a tuple\n",
    "            if self.split_rule==(-1,None):\n",
    "                self.label=round((sum(train_labels)/len(train_labels)))\n",
    "                self.train_data=train_data\n",
    "                self.train_labels=train_labels                 \n",
    "            else:\n",
    "                left_ind=train_data[...,self.split_rule[0]]<self.split_rule[1]\n",
    "                right_ind=train_data[...,self.split_rule[0]]>=self.split_rule[1]\n",
    "                self.left=Nodes()\n",
    "                self.right=Nodes()\n",
    "                self.left.parent=self\n",
    "                self.left.depth=self.depth+1\n",
    "                self.right.parent=self\n",
    "                self.right.depth=self.depth+1\n",
    "                self.left.GrowTree(max_depth,train_data[left_ind], train_labels[left_ind])\n",
    "                self.right.GrowTree(max_depth,train_data[right_ind], train_labels[right_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_split(train_data,train_labels):\n",
    "    n_feature=len(train_data[0])\n",
    "    H_after=[]\n",
    "    ij_value=[]\n",
    "    for i in range(n_feature):\n",
    "        sort_ind=train_data[...,i].argsort()\n",
    "        feature=train_data[...,i][sort_ind]\n",
    "        label=train_labels[sort_ind]        \n",
    "        for j in range(len(label)-1):\n",
    "            if feature[j]!=feature[j+1]:\n",
    "                n_left=j+1\n",
    "                n_right=len(label)-n_left\n",
    "                left_1=sum(label[0:n_left])\n",
    "                right_1=sum(label[n_left:len(label)])\n",
    "                p1_left=(left_1/n_left) or 0.0001\n",
    "                p0_left=(1-p1_left) or 0.0001\n",
    "                p1_right=(right_1/n_right) or 0.0001\n",
    "                p0_right=(1-p1_right) or 0.0001\n",
    "                entropy_left=-(p1_left*np.log2(p1_left)+p0_left*np.log2(p0_left))\n",
    "                enrtopy_right=-(p1_right*np.log2(p1_right)+p0_right*np.log2(p0_right))            \n",
    "                H_after.append((n_left*entropy_left+n_right*enrtopy_right)/(n_left+n_right))                \n",
    "                ij_value.append((i,feature[j+1]))\n",
    "    if H_after==[]:\n",
    "        split=(-1,None)\n",
    "    else:\n",
    "        index=H_after.index(min(H_after))\n",
    "        split=ij_value[index]\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self,max_depth=-1):\n",
    "        self.max_depth=max_depth\n",
    "        self.tree=Nodes()\n",
    "    def train(self, train_data, train_labels,random_feature=-1):\n",
    "        self.tree.GrowTree(self.max_depth,train_data, train_labels,random_feature)\n",
    "    def predict(self,test_data):\n",
    "        return np.array([prediction(self.tree,i) for i in test_data])\n",
    "    def score(self,valid_data,valid_labels):\n",
    "        predictions=np.array([prediction(self.tree,i) for i in valid_data])\n",
    "        return (sum(predictions==valid_labels)/len(valid_labels))\n",
    "    def path(self,data_point,feature_name,label_name):\n",
    "        Tree=self.tree\n",
    "        while Tree.split_rule[0]!=-1:\n",
    "            if data_point[Tree.split_rule[0]]<Tree.split_rule[1]:\n",
    "                print('\"',feature_name[Tree.split_rule[0]],'\"','<',Tree.split_rule[1])\n",
    "                Tree=Tree.left\n",
    "            else:\n",
    "                print('\"',feature_name[Tree.split_rule[0]],'\"','>=',Tree.split_rule[1])\n",
    "                Tree=Tree.right\n",
    "        print('Therefore this email is',label_name[int(Tree.label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(Tree,data):\n",
    "    while Tree.split_rule[0]!=-1:\n",
    "        if data[Tree.split_rule[0]]<Tree.split_rule[1]:\n",
    "            Tree=Tree.left\n",
    "        else:\n",
    "            Tree=Tree.right\n",
    "    return Tree.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self,n_trees=10,max_depth=10,sample_size=-1,n_feature=-1):\n",
    "        self.n_trees=n_trees\n",
    "        self.max_depth=max_depth\n",
    "        self.sample_size=sample_size\n",
    "        self.n_feature=n_feature\n",
    "        self.trees=[]\n",
    "    def train(self, train_data, train_labels):\n",
    "        if self.sample_size==-1:\n",
    "            self.sample_size=len(train_labels)\n",
    "        if self.n_feature==-1:\n",
    "            self.n_feature=int(round(np.sqrt(train_data.shape[1])))\n",
    "        for i in range(self.n_trees):\n",
    "            sample_ind=np.random.randint(0,len(train_labels),self.sample_size)\n",
    "            sample_data=train_data[sample_ind]\n",
    "            sample_label=train_labels[sample_ind]\n",
    "            self.trees.append(DecisionTree(self.max_depth))\n",
    "            self.trees[i].train(train_data=sample_data, train_labels=sample_label,random_feature=self.n_feature)\n",
    "    def predict(self,test_data):\n",
    "        pred=[]\n",
    "        for i in range(self.n_trees):\n",
    "            pred.append(self.trees[i].predict(test_data))\n",
    "        return (np.array(pred)).mean(0).round()\n",
    "    def score(self,valid_data,valid_labels):\n",
    "        predictions=self.predict(valid_data)\n",
    "        return (sum(predictions==valid_labels)/len(valid_labels))   \n",
    "    def common_root(self,feature_name):\n",
    "        rules=[]\n",
    "        for i in range(self.n_trees):\n",
    "            rules.append(self.trees[i].tree.split_rule)\n",
    "        rule_name=[]\n",
    "        rule_count=[]\n",
    "        for j in set(rules):\n",
    "            rule_name.append(j)\n",
    "            rule_count.append(rules.count(j))\n",
    "        rule_ind=np.array(rule_count).argsort()\n",
    "        for j in rule_ind[::-1]:\n",
    "            print('\"',feature_name[rule_name[j][0]],'\"','<',rule_name[j][1],':',rule_count[j],'trees')\n",
    "    def common_root_split(self,data_point,feature_name):\n",
    "        rules=[]\n",
    "        for i in range(self.n_trees):\n",
    "            rules.append(self.trees[i].tree.split_rule)\n",
    "        rule_name=[]\n",
    "        rule_count=[]\n",
    "        for j in set(rules):\n",
    "            rule_name.append(j)\n",
    "            rule_count.append(rules.count(j))\n",
    "        rule_ind=np.array(rule_count).argsort()\n",
    "        for j in rule_ind[::-1]:\n",
    "            if data_point[rule_name[j][0]]<rule_name[j][1]:\n",
    "                print('\"',feature_name[rule_name[j][0]],'\"','<',rule_name[j][1],':',rule_count[j],'trees')\n",
    "            else:\n",
    "                print('\"',feature_name[rule_name[j][0]],'\"','>=',rule_name[j][1],':',rule_count[j],'trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Classifier=DecisionTree(max_depth=25)\n",
    "Classifier.train(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82559856555215694"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier.score(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79725738396624468"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier.score(valid_set,valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Classifier1=RandomForest(n_trees=10,max_depth=25)\n",
    "Classifier1.train(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96408606687058329"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier1.score(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94472573839662444"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier1.score(valid_set,valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_name=['ham','spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" enron \" < 1\n",
      "\" 2001 \" < 1\n",
      "\" http \" >= 1\n",
      "\" vince \" < 1\n",
      "Therefore this email is spam\n"
     ]
    }
   ],
   "source": [
    "# Tree visualization.\n",
    "Classifier.path(valid_set[1],feature_name,label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" enron \" < 1\n",
      "\" 2001 \" < 1\n",
      "\" http \" < 1\n",
      "\" thanks \" >= 1\n",
      "\" this \" < 5\n",
      "\" no \" < 1\n",
      "\" your \" >= 2\n",
      "\" vince \" < 1\n",
      "\" you \" < 3\n",
      "\" but \" < 2\n",
      "Therefore this email is ham\n"
     ]
    }
   ],
   "source": [
    "Classifier.path(valid_set[2],feature_name,label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" 2000 \" < 1 : 2 trees\n",
      "\" enron \" < 1 : 2 trees\n",
      "\" hou \" < 1 : 1 trees\n",
      "\" please \" < 1 : 1 trees\n",
      "\" if \" < 1 : 1 trees\n",
      "\" subject \" < 2 : 1 trees\n",
      "\" 2001 \" < 1 : 1 trees\n",
      "\" that \" < 1 : 1 trees\n"
     ]
    }
   ],
   "source": [
    "# Random forest visualization.\n",
    "Classifier1.common_root(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" 2000 \" < 1 : 2 trees\n",
      "\" enron \" < 1 : 2 trees\n",
      "\" hou \" < 1 : 1 trees\n",
      "\" please \" < 1 : 1 trees\n",
      "\" if \" < 1 : 1 trees\n",
      "\" subject \" < 2 : 1 trees\n",
      "\" 2001 \" < 1 : 1 trees\n",
      "\" that \" >= 1 : 1 trees\n"
     ]
    }
   ],
   "source": [
    "Classifier1.common_root_split(valid_set[1],feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" 2000 \" < 1 : 2 trees\n",
      "\" enron \" >= 1 : 2 trees\n",
      "\" hou \" < 1 : 1 trees\n",
      "\" please \" >= 1 : 1 trees\n",
      "\" if \" < 1 : 1 trees\n",
      "\" subject \" < 2 : 1 trees\n",
      "\" 2001 \" < 1 : 1 trees\n",
      "\" that \" >= 1 : 1 trees\n"
     ]
    }
   ],
   "source": [
    "Classifier1.common_root_split(valid_set[6],feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
